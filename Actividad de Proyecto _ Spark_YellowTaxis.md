# Bienvenido a la Actividad de Proyecto
Como ya se mencionÃ³ anteriormente en esta actividad estarÃ¡s usando Apache Spark y su interface para Python PySpark para resolver ciertos ejercicios sobre los datos de Taxis de NYC.

Este archivo en el que vas a estar trabajando es conocido como un Notebook y estÃ¡ compuesto por celdas de cÃ³digo, en este caso en lenguaje Python, para ejecutar una celda puedes dar click sobre ella y luego presionar el botÃ³n ![BotÃ³n de play](https://i.ibb.co/9hvVpCK/Captura-de-pantalla-de-2021-07-14-14-18-01.png) o presionar Ctrl+Enter.

## 1. Crear una sesiÃ³n en Spark
Esta sesiÃ³n nos permite conectarnos al cluster Spark que desplegamos con anterioridad.


```python
from pyspark.sql import SparkSession

spark = SparkSession.\
        builder.\
        appName("pyspark-notebook").\
        master("spark://spark-master:7077").\
        config("spark.executor.memory", "512m").\
        getOrCreate()

spark.sparkContext.setLogLevel("OFF")
```

    24/06/12 13:27:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
    Setting default log level to "WARN".
    To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).


## 2. Leer los datos
En un paso anterior subiste 2 archivos a la carpeta __datos__, ahora vamos a leerlos y explorarlos antes de realizar los ejercicios.


```python
# Para leer los datos necesitas la ruta del archivo e indicar si tienen una cabecera o no, que en este caso si la tienen.
datos_2019 = spark.read.csv("../data/yellow_tripdata_2019-01.csv", header=True)
# Para visualizar los datos que leiste debes usar la funciÃ³n show e indicar el nÃºmero de filas, en este caso 5.
datos_2019.show(n=5)
```

                                                                                    

    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    |VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|
    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    |       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|         1.50|         1|                 N|         151|         239|           1|          7|  0.5|    0.5|      1.65|           0|                  0.3|        9.95|                null|
    |       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|              1|         2.60|         1|                 N|         239|         246|           1|         14|  0.5|    0.5|         1|           0|                  0.3|        16.3|                null|
    |       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|              3|          .00|         1|                 N|         236|         236|           1|        4.5|  0.5|    0.5|         0|           0|                  0.3|         5.8|                null|
    |       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|              5|          .00|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|        7.55|                null|
    |       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|              5|          .00|         2|                 N|         193|         193|           2|         52|    0|    0.5|         0|           0|                  0.3|       55.55|                null|
    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    only showing top 5 rows
    



```python
datos_2013 = spark.read.csv("../data/yellow_tripdata_2013-01.csv", header=True)
datos_2013.show(n=5)
```

    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    |vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|      trip_distance|   pickup_longitude|   pickup_latitude|rate_code|store_and_fwd_flag|  dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|
    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    |      CMT|2013-01-01 15:11:48|2013-01-01 15:18:10|              4|                  1|-73.978165000000004|40.757976999999997|        1|                 N|-73.989840000000001|40.751173000000001|         CSH|        6.5|        0|    0.5|         0|           0|           7|
    |      CMT|2013-01-06 00:18:35|2013-01-06 00:22:54|              1|                1.5|-74.006680000000003|40.731780999999998|        1|                 N|-73.994499000000005|40.750658999999999|         CSH|          6|      0.5|    0.5|         0|           0|           7|
    |      CMT|2013-01-05 18:49:41|2013-01-05 18:54:23|              1| 1.1000000000000001|         -74.004711|40.737769999999998|        1|                 N|-74.009831000000005|40.725999999999999|         CSH|        5.5|        1|    0.5|         0|           0|           7|
    |      CMT|2013-01-07 23:54:15|2013-01-07 23:58:20|              2|0.69999999999999996|-73.974599999999995|40.759945000000002|        1|                 N|-73.984736999999996|40.759388000000001|         CSH|          5|      0.5|    0.5|         0|           0|           6|
    |      CMT|2013-01-07 23:25:03|2013-01-07 23:34:24|              1| 2.1000000000000001|-73.976252000000002|         40.748528|        1|                 N|-74.002583000000001|40.747866999999999|         CSH|        9.5|      0.5|    0.5|         0|           0|        10.5|
    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    only showing top 5 rows
    


## Ejercicios
A continuaciÃ³n, vas a encontrar 2 ejercicios resueltos y explicados y uno para que completes de acuerdo a las instrucciones. **Todos los ejercicios deben resolverse siguiendo el patrÃ³n Map Reduce**.

### Ejercicio 1. Contar la cantidad total de viajes 
ExplicaciÃ³n


```python
from operator import add # Requerido por la funciÃ³n reduceByKey

ruta_entrada = "../data/*"

# 1. Carga todos los archivos de datos en un RDD
archivos_entrada = spark.sparkContext.textFile(ruta_entrada)
```


```python
# 2. Lee los archivos lÃ­nea por lÃ­nea y aplica las siguientes operaciones:
#    1. Divide la lÃ­nea por comas
#    2. Filtra las lÃ­neas de acuerdo a la cantidad de columnas, sÃ³lo conserva las que tengan mÃ¡s de 1. AdemÃ¡s, evita que las lÃ­neas con los
#       los nombres de las columnas sean tenidas en cuenta
#    3. Por cada lÃ­nea genera un pareja (llave, valor) donde la llave corresponde al tipo de servicio (yellow, fhv) y el valor a a ser 1
#       En este caso la llave la determina la cantidad de columnas de la lÃ­nea, pues como observamos durante la exploraciÃ³n los registros
#       de FHV sÃ³lo tienen 6 columnas.
#    4. Ordena las parejas (llave, valor) por llave
#    5. Realiza la operaciÃ³n reduce por llave, aplicando la operaciÃ³n de suma (add), es decir, va a tomar todas las parejas (llave, valor)
#       con la misma llave y las va a sumar para asÃ­ generar la cantidad total de viajes para cada tipo de servicio
resultado_map_reduce = archivos_entrada.map(lambda linea: linea.split(",")) \
                                .filter(lambda linea: len(linea)>1 and "PULocationID" not in linea) \
                                .map(lambda linea: ("yellow",1) if len(linea) > 6 else ("fhv", 1)) \
                                .sortByKey()\
                                .reduceByKey(add)
```

                                                                                    


```python
# 4. Imprime los resultados en consola.
# En este caso usamos take y pasamos un valor de 2 dado que solo se van a generar 2 parejas (llave, valor), una por cada tipo de servicio
print(resultado_map_reduce.take(2))
```

    [Stage 17:===========================================>            (39 + 2) / 50]

    [('yellow', 22446376), ('fhv', 612593)]


                                                                                    

### Ejercicio 2. Contar las cantidad total de viajes por zona de recogida
ExplicaciÃ³n


```python
muestra = archivos_entrada.take(5)
for linea in muestra:
    print(linea)

```

    PAR1ï¿½dï¿½Lï¿½	        
    ï¿½ï¿½=ï¿½$7ï¿½'Öï¿½ï¿½5eï¿½$ ï¿½ï¿½ï¿½tY{ï¿½C,^Lå‡‰jj+ï¿½ï¿½$AH$ï¿½Û?ï¿½ï¿½ï¿½ß„.(ï¿½,ï¿½ï¿½]ï¿½ï¿½ï¿½ 3ï¿½Pï¿½mjï¿½ï¿½ï¿½ w-ï¿½vï¿½)ï¿½|Mï¿½vï¿½=ï¿½jï¿½ï¿½Fï¿½S3bitï¿½ï¿½ Í˜ï¿½dï¿½dï¿½y4ï¿½Bsï¿½ï¿½ï¿½Æ“ï¿½4w;ß¦ï¿½î‘ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½<ï¿½\-wqï¿½u]ï¿½ï¿½.3.nï¿½ï¿½Aï¿½K(ß›ï¿½Ğ„ï¿½&ï¿½Sd8Hï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½X8ï¿½ï¿½mï¿½ï¿½6ï¿½	ï¿½Fï¿½Kï¿½ï¿½ï¿½ï¿½BtK*ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½ï¿½ï¿½e9}:;X>ï¿½3ï¿½'ï¿½Ã¾ï¿½ï¿½=ï¿½ï¿½ï¿½ï¿½Cï¿½Ê`ï¿½PxT^0j|ï¿½ï¿½mPï¿½jï¿½ï¿½ï¿½7
    ï¿½ï¿½fï¿½lï¿½Uï¿½ï¿½ï¿½S	nï¿½İ¦ï¿½ï¿½ï¿½ Y:ï¿½ï¿½ï¿½Æµï¿½ï¿½('_ï¿½[JM[ï¿½ï¿½ï¿½m)5mï¿½l
    ï¿½Ô·ï¿½wï¿½ï¿½ï¿½nï¿½ï¿½ï¿½-ï¿½ï¿½ï¿½_ï¿½4ï¿½ï¿½ É“gï¿½gï¿½Mï¿½`ï¿½.Vİ¡}ï¿½Fï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½I"ï¿½ ï¿½Pï¿½;+ï¿½4ï¿½t\ï¿½ï¿½BWHï¿½ï¿½ï¿½g[7ï¿½ï¿½ï¿½Gï¿½J#ï¿½V&Oï¿½Ä·Uï¿½?gï¿½ï¿½U"ï¿½ï¿½ï¿½&/'ï¿½*c
    ï¿½7İŸï¿½bï¿½ï¿½ï¿½Qeï¿½O4}ï¿½d ï¿½ï¿½sï¿½?İ†S"|


                                                                                    

Con esta informaciÃ³n confirmamos que por alguna razÃ³n el texto se corrompe 
intentarÃ© solucionarlo  mediante operaciones separadas


```python
datos_2019.show(n=5) 
```

    [Stage 20:>                                                         (0 + 1) / 1]

    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    |VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|
    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    |       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|              1|         1.50|         1|                 N|         151|         239|           1|          7|  0.5|    0.5|      1.65|           0|                  0.3|        9.95|                null|
    |       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|              1|         2.60|         1|                 N|         239|         246|           1|         14|  0.5|    0.5|         1|           0|                  0.3|        16.3|                null|
    |       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|              3|          .00|         1|                 N|         236|         236|           1|        4.5|  0.5|    0.5|         0|           0|                  0.3|         5.8|                null|
    |       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|              5|          .00|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|        7.55|                null|
    |       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|              5|          .00|         2|                 N|         193|         193|           2|         52|    0|    0.5|         0|           0|                  0.3|       55.55|                null|
    +--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+
    only showing top 5 rows
    


                                                                                    


```python
datos_2013.show(n=5)
```

                                                                                    

    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    |vendor_id|    pickup_datetime|   dropoff_datetime|passenger_count|      trip_distance|   pickup_longitude|   pickup_latitude|rate_code|store_and_fwd_flag|  dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|
    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    |      CMT|2013-01-01 15:11:48|2013-01-01 15:18:10|              4|                  1|-73.978165000000004|40.757976999999997|        1|                 N|-73.989840000000001|40.751173000000001|         CSH|        6.5|        0|    0.5|         0|           0|           7|
    |      CMT|2013-01-06 00:18:35|2013-01-06 00:22:54|              1|                1.5|-74.006680000000003|40.731780999999998|        1|                 N|-73.994499000000005|40.750658999999999|         CSH|          6|      0.5|    0.5|         0|           0|           7|
    |      CMT|2013-01-05 18:49:41|2013-01-05 18:54:23|              1| 1.1000000000000001|         -74.004711|40.737769999999998|        1|                 N|-74.009831000000005|40.725999999999999|         CSH|        5.5|        1|    0.5|         0|           0|           7|
    |      CMT|2013-01-07 23:54:15|2013-01-07 23:58:20|              2|0.69999999999999996|-73.974599999999995|40.759945000000002|        1|                 N|-73.984736999999996|40.759388000000001|         CSH|          5|      0.5|    0.5|         0|           0|           6|
    |      CMT|2013-01-07 23:25:03|2013-01-07 23:34:24|              1| 2.1000000000000001|-73.976252000000002|         40.748528|        1|                 N|-74.002583000000001|40.747866999999999|         CSH|        9.5|      0.5|    0.5|         0|           0|        10.5|
    +---------+-------------------+-------------------+---------------+-------------------+-------------------+------------------+---------+------------------+-------------------+------------------+------------+-----------+---------+-------+----------+------------+------------+
    only showing top 5 rows
    


Parece que el problema surge de la uniÃ³n de los dataframes.


```python
muestra_entrada = archivos_entrada.take(10)
for linea in muestra_entrada:
    print(linea)
```

    PAR1ï¿½dï¿½Lï¿½	        
    ï¿½ï¿½=ï¿½$7ï¿½'Öï¿½ï¿½5eï¿½$ ï¿½ï¿½ï¿½tY{ï¿½C,^Lå‡‰jj+ï¿½ï¿½$AH$ï¿½Û?ï¿½ï¿½ï¿½ß„.(ï¿½,ï¿½ï¿½]ï¿½ï¿½ï¿½ 3ï¿½Pï¿½mjï¿½ï¿½ï¿½ w-ï¿½vï¿½)ï¿½|Mï¿½vï¿½=ï¿½jï¿½ï¿½Fï¿½S3bitï¿½ï¿½ Í˜ï¿½dï¿½dï¿½y4ï¿½Bsï¿½ï¿½ï¿½Æ“ï¿½4w;ß¦ï¿½î‘ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½<ï¿½\-wqï¿½u]ï¿½ï¿½.3.nï¿½ï¿½Aï¿½K(ß›ï¿½Ğ„ï¿½&ï¿½Sd8Hï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½X8ï¿½ï¿½mï¿½ï¿½6ï¿½	ï¿½Fï¿½Kï¿½ï¿½ï¿½ï¿½BtK*ï¿½ï¿½ï¿½tï¿½ï¿½ï¿½ï¿½ï¿½e9}:;X>ï¿½3ï¿½'ï¿½Ã¾ï¿½ï¿½=ï¿½ï¿½ï¿½ï¿½Cï¿½Ê`ï¿½PxT^0j|ï¿½ï¿½mPï¿½jï¿½ï¿½ï¿½7
    ï¿½ï¿½fï¿½lï¿½Uï¿½ï¿½ï¿½S	nï¿½İ¦ï¿½ï¿½ï¿½ Y:ï¿½ï¿½ï¿½Æµï¿½ï¿½('_ï¿½[JM[ï¿½ï¿½ï¿½m)5mï¿½l
    ï¿½Ô·ï¿½wï¿½ï¿½ï¿½nï¿½ï¿½ï¿½-ï¿½ï¿½ï¿½_ï¿½4ï¿½ï¿½ É“gï¿½gï¿½Mï¿½`ï¿½.Vİ¡}ï¿½Fï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½I"ï¿½ ï¿½Pï¿½;+ï¿½4ï¿½t\ï¿½ï¿½BWHï¿½ï¿½ï¿½g[7ï¿½ï¿½ï¿½Gï¿½J#ï¿½V&Oï¿½Ä·Uï¿½?gï¿½ï¿½U"ï¿½ï¿½ï¿½&/'ï¿½*c
    ï¿½7İŸï¿½bï¿½ï¿½ï¿½Qeï¿½O4}ï¿½d ï¿½ï¿½sï¿½?İ†S"|
    ï¿½Lï¿½bT%ï¿½) ï¿½ï¿½2ï¿½^Hß¶ï¿½BVmï¿½ï¿½ï¿½ï¿½\,ï¿½ï¿½ï¿½qDï¿½~ï¿½obï¿½Bï¿½ï¿½ï¿½9ï¿½kï¿½6Aï¿½ï¿½ï¿½ï¿½ï¿½ï¿½F:ï¿½ï¿½*/{\ï¿½ï¿½ï¿½ï¿½tw3ï¿½-Pï¿½rï¿½Vï¿½ï¿½\ï¿½]ï¿½ï¿½Wï¿½ï¿½.ï¿½ï¿½ï¿½{Yï¿½THï¿½<ï¿½ï¿½$ï¿½rï¿½MEï¿½ï¿½ï¿½ï¿½ï¿½ï¿½1*ï¿½ï¿½#2ï¿½[|ï¿½ï¿½o37ï¿½ï¿½\Iï¿½._aï¿½ï¿½ ï¿½P7ï¿½ï¿½\|ï¿½+]0ï¿½ï¿½ï¿½r)ï¿½:Fï¿½TQYEï¿½CLï¿½ï¿½wï¿½ï¿½kï¿½ï¿½
    tï¿½Ò„}ï¿½ï¿½$ï¿½ï¿½@ï¿½4C~ï¿½Cï¿½pkï¿½ï¿½Êƒï¿½ï¿½[ï¿½Ljï¿½ï¿½ï¿½Cï¿½8ï¿½Mï¿½2`wï¿½.cï¿½5sAï¿½ï¿½oï¿½ï¿½ï¿½~)h*ï¿½ï¿½ï¿½ï¿½1r qiï¿½ï¿½ï¿½Pxï¿½ï¿½ï¿½ï¿½ï¿½Ldï¿½Bï¿½ï¿½
    5ï¿½ï¿½h7tï¿½ï¿½ï¿½ÂBsaï¿½ï¿½`Sï¿½ï¿½ï¿½]Fd
    =uï¿½*;ï¿½#X.ï¿½ï¿½bË  ï¿½ï¿½nnï¿½@ï¿½}14ï¿½É—ï¿½ï¿½nkï¿½Xï¿½zïœ ï¿½9?}ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½|ï¿½;e]ï¿½(sbÕ¡ ï¿½*ï¿½4z((ï¿½~ï¿½ï¿½ïƒ˜ï¿½eï¿½ï¿½eï¿½[Ënï¿½ï¿½ï¿½ï¿½}ï¿½ï¿½#ï¿½ï¿½}~*mï¿½Ö‘ï¿½aï¿½UZï¿½ï¿½ï¿½G9ï¿½ï¿½Iï¿½ï¿½Eï¿½9dND&ï¿½))ï¿½yï¿½Eï¿½ï¿½ï¿½ï¿½(Ö•Dï¿½Nï¿½ï¿½Âª(
    ï¿½,ï¿½(Eï¿½v^Eï¿½ï¿½]MÜ£eï¿½ï¿½ï¿½ï¿½9ï¿½)Ô•ï¿½Sï¿½ë®¸ï¿½T}ï¿½;_ï¿½ï¿½ï¿½Zï¿½ï¿½aï¿½ï¿½ï¿½ï¿½kï¿½ï¿½ï¿½Zï¿½Uï¿½ï¿½Mrgï¿½ï¿½81ï¿½Qï¿½Rï¿½ï¿½4 ï¿½_%gï¿½ï¿½ï¿½ï¿½ï¿½J>ï¿½&ZA.*|Z#"ï¿½zLï¿½ï¿½ï¿½ï¿½ï¿½ï¿½nï¿½Ë„Ç¡ï¿½=î”¦ï¿½pï¿½Wï¿½ï¿½^ï¿½iï¿½ï¿½Äï¿½ï¿½ï¿½ï¿½Cï¿½ï¿½bï¿½ï¿½ï¿½U*=Mï¿½Iï¿½;y~ï¿½ï¿½ï¿½jï¿½Z.FW}e&ï¿½ï¿½ï¿½ï¿½ï¿½QLï¿½D4ï¿½Å˜mï¿½cï¿½>ï¿½Uï¿½ï¿½(xï¿½)Gï¿½ï¿½>{ygï¿½Ç!o/ï¿½Hï¿½Tï¿½ï¿½ï¿½Ã£ï¿½	-ï¿½4ï¿½fï¿½ï¿½,ï¿½ï¿½r4`ï¿½zIï¿½xGÏ¦Sï¿½ï¿½Ú„ï¿½ï¿½~ï¿½ï¿½ï¿½fï¿½Poï¿½@ï¿½fwï¿½tÖ‡4ï¿½ï¿½


En efecto, estÃ¡ roto
Voy a intentar armar el RDD unicamente con los datos de 2 de ellos en vez de los 4 archivos presentes, unicamente tomando los csv


```python
from operator import add # Requerido por la funciÃ³n reduceByKey

# Rutas especÃ­ficas de los archivos deseados
rutas_entrada = [
    "../data/yellow_tripdata_2019-01.csv",
    "../data/yellow_tripdata_2013-01.csv"
]

# Cargar los archivos en un RDD
archivos_entrada = spark.sparkContext.textFile(",".join(rutas_entrada))
```


```python
muestra_entrada = archivos_entrada.take(10)
for linea in muestra_entrada:
    print(linea)
```

    VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge
    1,2019-01-01 00:46:40,2019-01-01 00:53:20,1,1.50,1,N,151,239,1,7,0.5,0.5,1.65,0,0.3,9.95,
    1,2019-01-01 00:59:47,2019-01-01 01:18:59,1,2.60,1,N,239,246,1,14,0.5,0.5,1,0,0.3,16.3,
    2,2018-12-21 13:48:30,2018-12-21 13:52:40,3,.00,1,N,236,236,1,4.5,0.5,0.5,0,0,0.3,5.8,
    2,2018-11-28 15:52:25,2018-11-28 15:55:45,5,.00,1,N,193,193,2,3.5,0.5,0.5,0,0,0.3,7.55,
    2,2018-11-28 15:56:57,2018-11-28 15:58:33,5,.00,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,
    2,2018-11-28 16:25:49,2018-11-28 16:28:26,5,.00,1,N,193,193,2,3.5,0.5,0.5,0,5.76,0.3,13.31,
    2,2018-11-28 16:29:37,2018-11-28 16:33:43,5,.00,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,
    1,2019-01-01 00:21:28,2019-01-01 00:28:37,1,1.30,1,N,163,229,1,6.5,0.5,0.5,1.25,0,0.3,9.05,
    1,2019-01-01 00:32:01,2019-01-01 00:45:39,1,3.70,1,N,229,7,1,13.5,0.5,0.5,3.7,0,0.3,18.5,


Este nuevo ya no estÃ¡ roto!


```python
# 1. Carga todos los archivos de datos. 
# Para este caso ya no es necesario cargar los datos pues lo hicimos en el ejercicio anterior.

# 2. Lee los archivos lÃ­nea por lÃ­nea y aplica las siguientes operaciones:
#    1. Divide la lÃ­nea por comas
#    2. Filtra las lÃ­neas de acuerdo a la cantidad de columnas, sÃ³lo conserva las que tengan mÃ¡s de 1. AdemÃ¡s, evita que las lÃ­neas con los
#       los nombres de las columnas sean tenidas en cuenta
#    3. Por cada lÃ­nea genera un pareja (llave, valor) donde la llave corresponde a la zona de recogida (PULocationID) y el valor a a ser 1
#       En este caso la llave la determina la cantidad de columnas de la lÃ­nea, pues como observamos durante la exploraciÃ³n los registros
#       de FHV tienen el PULocationID es una columna diferente a los Yellow. 
#       Recordemos que en los lenguajes de programaciÃ³n comienzan a contar desde 0 por esto para los taxis FHV se hace linea[3] y para los Yellow linea[7]
#    4. Ordena las parejas (llave, valor) por llave
#    5. Realiza la operaciÃ³n reduce por llave, aplicando la operaciÃ³n de suma (add), es decir, va a tomar todas las parejas (llave, valor)
#       con la misma llave y las va a sumar para asÃ­ generar la cantidad total de viajes para cada zona de recogida
#    6. Ordena los resultados del reduce por su valor, que en este caso es la cantidad de viajes de cada zona de recogida.
resultado_map_reduce_2 = archivos_entrada.map(lambda linea: linea.split(",")) \
                                .filter(lambda linea: len(linea)>1 and "PULocationID" not in linea) \
                                .map(lambda linea: (linea[7],1) if len(linea) > 6 else (linea[3], 1)) \
                                .sortByKey() \
                                .reduceByKey(add) \
                                .sortBy(lambda par: par[1], ascending=False)
```

                                                                                    

Ahora revisar si la informaciÃ³n ya saliÃ³ de manera correcta


```python
# 4. Imprime los resultados en consola.
# En este caso sÃ³lo vamos a tomar las 10 zonas de recogida con mayor cantidad de viajes
print(resultado_map_reduce_2.take(10))
```

                                                                                    

    [('1', 14456513), ('237', 332473), ('236', 323008), ('161', 312392), ('162', 277166), ('230', 263646), ('186', 260712), ('48', 240903), ('2', 239170), ('170', 238978)]


### Ejercicio 3. Top 5 lugares de llegada
ExplicaciÃ³n

Por lo que entiendo, esto debe de ejecutarse para poder verificar las zonas de llegada, y pedir unicamente el top 5 de ellos


```python
# 1. Carga todos los archivos de datos. 
# Para este caso ya no es necesario cargar los datos pues lo hicimos en el ejercicio anterior.

# 2. Lee los archivos lÃ­nea por lÃ­nea y aplica las siguientes operaciones:
#    1. Divide la lÃ­nea por comas
#    2. Filtra las lÃ­neas de acuerdo a la cantidad de columnas, sÃ³lo conserva las que tengan mÃ¡s de 1. AdemÃ¡s, evita que las lÃ­neas con los
#       los nombres de las columnas sean tenidas en cuenta
#    3. Por cada lÃ­nea genera un pareja (llave, valor) donde la llave corresponde a la zona de recogida (PULocationID) y el valor a a ser 1
#       En este caso la llave la determina la cantidad de columnas de la lÃ­nea, pues como observamos durante la exploraciÃ³n los registros
#       de FHV tienen el PULocationID es una columna diferente a los Yellow. 
#       Recordemos que en los lenguajes de programaciÃ³n comienzan a contar desde 0 por esto para los taxis FHV se hace linea[3] y para los Yellow linea[7]
#    4. Ordena las parejas (llave, valor) por llave
#    5. Realiza la operaciÃ³n reduce por llave, aplicando la operaciÃ³n de suma (add), es decir, va a tomar todas las parejas (llave, valor)
#       con la misma llave y las va a sumar para asÃ­ generar la cantidad total de viajes para cada zona de recogida
#    6. Ordena los resultados del reduce por su valor, que en este caso es la cantidad de viajes de cada zona de recogida.
resultado_map_reduce_3 = archivos_entrada.map(lambda linea: linea.split(",")) \
                                .filter(lambda linea: len(linea)>1 and "DOLocationID" not in linea) \
                                .map(lambda linea: (linea[8],1) if len(linea) > 6 else (linea[3], 1)) \
                                .sortByKey() \
                                .reduceByKey(add) \
                                .sortBy(lambda par: par[1], ascending=False)
```

                                                                                    


```python
# 5. Imprime los resultados en consola.
# En este caso sÃ³lo vamos a tomar las 5 zonas de llegada con mayor cantidad de viajes
print(resultado_map_reduce_3.take(5))
```

                                                                                    

    [('', 7326207), ('N', 7285231), ('236', 334323), ('237', 296185), ('161', 293782)]


Â¡Tecnicamente, con esto terminarÃ­a este ejercicio!
